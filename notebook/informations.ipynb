{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "    <div style=\"width: 70%; float: left\">\n",
    "        <h1>Intelligence artificielle et Celeste </h1>\n",
    "        <h4>Réalisé par : Samir Belfaquir, Romain Corbeau, Tristan LeSaux et Nicolas Dupré-Pawlak</h4>\n",
    "    </div>\n",
    "    <img style=\"width:20%; height: auto;\" src=\"img/CelesteLogo.png\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Présentation du projet </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Démonstration du jeu</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Objectifs:</h2>\n",
    "<ul>\n",
    "<li> Random Agent </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li> Adaptation d'un algorithme utilisé sur Pong </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul>\n",
    "<li> Algorithmes avancés </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div>\n",
    "    <h1> Lancement du projet avec un random agent</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import retro\n",
    "\n",
    "def main():\n",
    "    env = retro.make(game='Celeste-GBA', state='Level1')\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        obs, rew, done, info =  env.step(env.action_space.sample())\n",
    "        env.render()\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "    env.close()\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "    #main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1>Résultat attendu : </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"middle\">\n",
       "    <video width=\"50%\" controls>\n",
       "        <source src=\"records/MP4/randomRun.mp4\" type=\"video/mp4\">\n",
       "    </video>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "    <video width=\"50%\" controls>\n",
    "        <source src=\"records/MP4/randomRun.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Intelligence artificelle et jeux vidéo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>L'apprentissage par renforcement</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Qu’est-ce que l’apprentissage par renforcement ?</h2>\n",
    "<div style=\"display: flex\">\n",
    "<img width=40% src=\"img/machine-learning.png\" />\n",
    "    \n",
    "<img width=\"60%\" src=\"img/ApprentissageParRenforcement.PNG\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Markov Decision Process</h2>\n",
    "<div style=\"display: flex\">\n",
    "<div>\n",
    "    Les MDP sont des automates définis par le quadruplet : { S, A, T, R }.\n",
    "    <ul>\n",
    "        <li>S -> L'ensemble des états</li>\n",
    "        <li>A -> L'ensemble des actions que l'agent choisi pour se déplacer dans l'automate.</li>\n",
    "        <li>T -> La fonction de transition permettant de passer de l'état s à s' à  l'aide de l'action a.</li>\n",
    "        <li>R -> La fonction remettant la récompense r quand l'agent passe de l'état s à s' en faisant l'action a (on l'appelle aussi fonction de coût).</li>\n",
    "    </ul>\n",
    "</div>\n",
    "<img width=38%; height=38%; src=\"img/mdp.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Google et l'Atari 2600</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "Depuis 2013, Google DeepMind, la filiale consacrée à l’intelligence artificielle et au deep-learning se consacre aux jeux Atari 2600. Ayant réalisé une étude sur 9 jeux mythiques de la console (dont Pong, Enduro et Private Eye), Google semble se concentrer sur l'apprentissage par renforcement qui permet de réaliser quelques fois des performances considérées comme surhumaines (notamment sur Pong et Enduro).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div align=\"middle\">\n",
       "    <video width=\"30%\" controls>\n",
       "        <source src=\"records/MP4/pong.mp4\" type=\"video/mp4\">\n",
       "    </video>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div align=\"middle\">\n",
    "    <video width=\"30%\" controls>\n",
    "        <source src=\"records/MP4/pong.mp4\" type=\"video/mp4\">\n",
    "    </video>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div>\n",
    "    <h1>Récupération et installation du projet</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2> Avec Binder </h2>\n",
    "<a href=\"https://mybinder.org/v2/gh/duprepNicolas/ter-celeste.git/main\">\n",
    "    <img src=\"https://mybinder.org/badge_logo.svg\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2> Sans Binder </h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "!git clone https://github.com/duprepNicolas/ter-celeste.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On se déplace dans le dossier\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "cd ter-celeste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Installation de gym retro"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "!pip3 install gym-retro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On déplace le dossier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "mv Celeste-GBA <Votre chemin d installation de Python en version 3.8 max>/Lib/site-packages/retro/data/stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On lance le projet"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "python3 projet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Quelques explications </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p> \n",
    "    Gym Retro est une plateforme d'apprentissage par renforcement pour les jeux rétro (GBA, Atari, NES, ...) développée par OpenAI. Cette librairie se base sur la fouille de données pour apprendre à se déplacer dans l'environnement.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p>\n",
    "    Pour configurer l'environnement autour de Celeste, il est nécessaire de modifier quelques fichiers:\n",
    "    <ul>\n",
    "        <li> data.json </li>\n",
    "        <li> scenario.json </li>\n",
    "        <li> level.state </li>\n",
    "        <li> metadata.json </li>\n",
    "        <li> rom.sha </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1> data.json </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div style=\"display: flex\">\n",
    "<p>\n",
    "    Ce fichier contient les adresses mémoires ainsi que le type des rewards.\n",
    "    Ces adresses sont décimales et le type représente le nombre d'octets que prend la valeur.\n",
    "</p>\n",
    "<img src=\"img/data.json.png\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1> scenario.json </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div style=\"display: flex\">\n",
    "    <div>\n",
    "Ce fichier communique avec data.json pour récupérer des variables et donne les informations importantes à l'agent telles que:\n",
    "    <ul>\n",
    "        <li> Quand est-ce qu'un épisode s'arrête ? </li>\n",
    "        <li> Dans quelles conditions l'agent récupérera un reward ? </li>\n",
    "        <li> Quelle est la valeur de chaque reward ? </li>\n",
    "    </ul>\n",
    "    </div>\n",
    "<img style=\"display=inline\" src=\"img/scenario.json.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1> level.state </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p>\n",
    "    C'est le fichier contenant l'état de départ.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1> metadata.json </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div>\n",
    "    Ce fichier permet à Gym-Retro de charger la state.\n",
    "</div>\n",
    "<img src=\"img/metadata.json.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1> rom.sha </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<p>\n",
    "    Ce fichier permet de vérifier que la rom lu correspond au bon jeu.\n",
    "    <br />\n",
    "    La fonction de hachage est SHA-1\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Perspective : de Pong à Celeste </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div style=\"text-align: -webkit-center\">\n",
    "    <img src=\"img/celeste_1.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> Etat de l'art </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2> Deep Learning </h2>\n",
    "<div style=\"text-align: -webkit-center; display: flex\">\n",
    "<img width=\"500px\" src=\"img/deepLearning.jpeg\" />\n",
    "<img width=\"600px\" src=\"img/dl2.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2> Algorithmes évolutionnistes </h2>\n",
    "<div style=\"text-align: -webkit-center\">\n",
    "<img width=\"400px\" src=\"img/robot.jpeg\" />\n",
    "<img width=\"400px\" src=\"img/algo-evolution.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h2>Monte Carlo Research </h2>\n",
    "<div style=\"text-align: -webkit-center\">\n",
    "<img src=\"img/mc.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>Sources</h1>\n",
    "\n",
    "<a href=\"https://www.numerama.com/sciences/175191-google-motive-ia-joue-mieux-a-vieux-jeu-atari.html\">Google motive son IA pour qu’elle joue mieux à un vieux jeu Atari</a> <br />\n",
    "<a href=\"https://arxiv.org/pdf/1606.01868v1.pdf\">Unifying Count-Based Exploration and Intrinsic Motivation</a> <br />\n",
    "<a href=\"https://k-actus.net/index.php/2018/11/21/lia-sattaque-aux-jeux-atari-2600/\">L’IA s’attaque aux jeux Atari 2600</a> <br />\n",
    "<a href=\"https://arxiv.org/pdf/1708.07902v3.pdf\">Deep Learning for Video Game Playing</a> <br />\n",
    "<a href=\"https://retro.readthedocs.io/en/latest/getting_started.html\"> Gym Retro by OpenAI </a> <br />\n",
    "<a href=\"https://karpathy.github.io/2016/05/31/rl/\">Deep Reinforcement Learning: Pong from Pixels</a><br />\n",
    "<a href=\"https://github.com/JeffRuLz/Celeste-Classic-GBA\"> Celeste version GBA </a><br />\n",
    "<a href=\"https://www.thinkopen.it/en/project/artificial-intelligence-state-of-the-art/\">Artificial Intelligence: state of the art</a><br />\n",
    "<a href=\"https://medium.com/aureliantactics/integrating-new-games-into-retro-gym-12b237d3ed75\">Integrating New Games into Retro Gym</a><br />\n",
    "<a href=\"https://courspython.com/apprendre-numpy.html\">Introduction à NumPy</a><br />\n",
    "<a href=\"https://spinningup.openai.com/en/latest/\">Welcome to Spinning Up in Deep RL!</a><br />\n",
    "<a href=\"https://moox.io/blog/keep-in-sync-git-repos-on-github-gitlab-bitbucket/\">Keep in sync your Git repos on GitHub, GitLab & Bitbucket</a><br />\n",
    "<a href=\"https://stable-baselines3.readthedocs.io/en/master/\">Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations</a><br />\n",
    "<a href=\"https://makina-corpus.com/blog/metier/2017/initiation-au-machine-learning-avec-python-theorie\">Initiation au Machine Learning avec Python - La théorie</a><br />\n",
    "<a href=\"https://medium.com/emergent-future/spam-detection-using-neural-networks-in-python-9b2b2a062272\">Spam detection using neural networks in Python</a><br />\n",
    "<a href=\"https://blog.octo.com/apprentissage-par-renforcement-de-la-theorie-a-la-pratique/\">Apprentissage par renforcement – de la théorie à la pratique</a><br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 style=\"text-align: center\"> One more thing... </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align: -webkit-center\">\n",
    "<a href=\"https://create.kahoot.it/details/celeste/ee90b33d-0e33-4841-8e61-e7552a2bfa9a\" target=\"_blank\"><img src=\"img/Kahoot-icon.jpg\" /></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"text-align: -webkit-center\">\n",
    "    <img src=\"https://tenor.com/view/lilo-and-stitch-mood-sad-gloomy-depressed-gif-11662158.gif\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
